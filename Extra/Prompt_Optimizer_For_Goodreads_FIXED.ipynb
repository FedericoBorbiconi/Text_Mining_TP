{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598b320d",
   "metadata": {},
   "source": [
    "# Prompt Optimizer para sistema de recomendaci√≥n (Goodreads)\n",
    "\n",
    "Este notebook permite evaluar si un prompt es pertinente para un sistema de recomendaci√≥n de libros de ficci√≥n y generar una versi√≥n mejorada del prompt para optimizar b√∫squedas sobre el dataset `goodreads_data.csv`.\n",
    "\n",
    "**‚ú® Funcionalidad principal: B√öSQUEDA AUTOM√ÅTICA EN GOODREADS**\n",
    "- Menciona un libro entre comillas (ej. \"similar a '1984'\")\n",
    "- El sistema lo busca autom√°ticamente en el dataset de Goodreads\n",
    "- Extrae metadata real: autor, g√©neros, rating, valoraciones, a√±o\n",
    "- Genera prompt mejorado con datos reales del dataset\n",
    "- **No necesitas ingresar manualmente ning√∫n dato**\n",
    "\n",
    "**Flujo**: 1) Configurar LLM (Gemini/OpenAI), 2) Cargar CSV, 3) Evaluar pertinencia, 4) B√∫squeda autom√°tica + Generar prompt mejorado.\n",
    "\n",
    "**Incluye modo `mock`** para pruebas sin consumir la API.\n",
    "\n",
    "---\n",
    "## ‚ö†Ô∏è Versi√≥n Corregida - Changelog:\n",
    "- ‚úÖ **B√∫squeda autom√°tica de libros en dataset de Goodreads**\n",
    "- ‚úÖ **Extracci√≥n autom√°tica de metadata (autor, g√©nero, rating, etc.)**\n",
    "- ‚úÖ Carga segura de API key (sin hardcodear)\n",
    "- ‚úÖ Implementaci√≥n de funci√≥n `generate_text()`\n",
    "- ‚úÖ Carga autom√°tica del dataset CSV\n",
    "- ‚úÖ Correcci√≥n de regex para extracci√≥n de JSON\n",
    "- ‚úÖ Mejora de la funci√≥n `improve_prompt()` con an√°lisis inteligente\n",
    "- ‚úÖ Eliminaci√≥n de documentaci√≥n duplicada\n",
    "- ‚úÖ Manejo robusto de errores con logging\n",
    "- ‚úÖ Validaci√≥n del dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install_deps",
   "metadata": {},
   "source": [
    "## 1. Verificaci√≥n de dependencias\n",
    "\n",
    "Verifica que los paquetes necesarios est√©n instalados. Si falta alguno, inst√°lalo con `uv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "install_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando dependencias necesarias:\n",
      "\n",
      "‚úì pandas est√° instalado\n",
      "‚úì python-dotenv est√° instalado\n",
      "\n",
      "Paquetes opcionales (seg√∫n proveedor LLM):\n",
      "‚úì google-generativeai est√° instalado\n",
      "‚úì openai est√° instalado\n",
      "\n",
      "============================================================\n",
      "üì¶ Si falta alg√∫n paquete, inst√°lalo con uv:\n",
      "   uv add pandas python-dotenv\n",
      "   uv add google-generativeai  # para Gemini\n",
      "   uv add openai               # para OpenAI\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verificar dependencias instaladas\n",
    "import sys\n",
    "\n",
    "def check_package(package_name, import_name=None):\n",
    "    \"\"\"Verifica si un paquete est√° disponible\"\"\"\n",
    "    import_name = import_name or package_name\n",
    "    try:\n",
    "        __import__(import_name)\n",
    "        print(f\"‚úì {package_name} est√° instalado\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(f\"‚úó {package_name} NO est√° instalado\")\n",
    "        return False\n",
    "\n",
    "print(\"Verificando dependencias necesarias:\\n\")\n",
    "\n",
    "# Verificar paquetes b√°sicos\n",
    "check_package('pandas')\n",
    "check_package('python-dotenv', 'dotenv')\n",
    "\n",
    "# Verificar paquetes opcionales seg√∫n proveedor\n",
    "print(\"\\nPaquetes opcionales (seg√∫n proveedor LLM):\")\n",
    "check_package('google-generativeai', 'google.generativeai')\n",
    "check_package('openai')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì¶ Si falta alg√∫n paquete, inst√°lalo con uv:\")\n",
    "print(\"   uv add pandas python-dotenv\")\n",
    "print(\"   uv add google-generativeai  # para Gemini\")\n",
    "print(\"   uv add openai               # para OpenAI\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_section",
   "metadata": {},
   "source": [
    "## 2. Imports y configuraci√≥n inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64740898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports completados\n"
     ]
    }
   ],
   "source": [
    "# Imports principales\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "import pandas as pd\n",
    "\n",
    "# Configurar logging para debugging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(levelname)s: %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Imports completados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7361d0",
   "metadata": {},
   "source": [
    "## 3. Configuraci√≥n del Modelo LLM y API Key\n",
    "\n",
    "Configura el proveedor de LLM (`gemini` o `openai`) y carga la API key de forma segura.\n",
    "\n",
    "**Opciones para cargar API key**:\n",
    "1. Variable de entorno (recomendado): `export GEMINI_API_KEY=tu_clave`\n",
    "2. Archivo externo: `api_key_gemini.txt` (no debe estar en git)\n",
    "3. Input manual del usuario (getpass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5215c2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: ‚úì Archivo .env encontrado y cargado\n",
      "INFO: ‚úì API key cargada desde variable de entorno GEMINI_API_KEY\n",
      "INFO: ‚úÖ Configuraci√≥n completa: gemini - models/gemini-2.0-flash-exp\n",
      "INFO: ‚úì API key cargada desde variable de entorno GEMINI_API_KEY\n",
      "INFO: ‚úÖ Configuraci√≥n completa: gemini - models/gemini-2.0-flash-exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: models/gemini-2.0-flash-exp\n",
      "Proveedor: gemini\n",
      "API Key configurada: S√≠ ‚úì\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n del modelo\n",
    "MODEL_NAME = 'models/gemini-2.0-flash-exp'  # o 'gpt-4o' para OpenAI\n",
    "provider = 'gemini'  # 'gemini' o 'openai'\n",
    "\n",
    "# Carga segura de API key con soporte para .env\n",
    "API_KEY = None\n",
    "\n",
    "# Intentar cargar variables de entorno desde archivo .env\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    if load_dotenv():  # Carga .env si existe\n",
    "        logger.info(\"‚úì Archivo .env encontrado y cargado\")\n",
    "except ImportError:\n",
    "    logger.debug(\"python-dotenv no instalado, continuando...\")\n",
    "\n",
    "# Opci√≥n 1: Cargar desde variable de entorno (incluye .env si se carg√≥)\n",
    "env_var_name = 'GEMINI_API_KEY' if provider == 'gemini' else 'OPENAI_API_KEY'\n",
    "API_KEY = os.environ.get(env_var_name)\n",
    "if API_KEY:\n",
    "    logger.info(f\"‚úì API key cargada desde variable de entorno {env_var_name}\")\n",
    "\n",
    "# Opci√≥n 2: Cargar desde archivo de texto (si existe)\n",
    "if not API_KEY:\n",
    "    api_key_file = Path('api_key_gemini.txt') if provider == 'gemini' else Path('api_key_openai.txt')\n",
    "    if api_key_file.exists():\n",
    "        with open(api_key_file, 'r') as f:\n",
    "            API_KEY = f.read().strip()\n",
    "        logger.info(f\"‚úì API key cargada desde archivo {api_key_file}\")\n",
    "\n",
    "# Opci√≥n 3: Solicitar al usuario\n",
    "if not API_KEY:\n",
    "    API_KEY = getpass(f'Ingresa tu API key para {provider} (entrada oculta): ')\n",
    "    logger.info(\"‚úì API key ingresada manualmente\")\n",
    "\n",
    "if not API_KEY:\n",
    "    logger.warning(\"‚ö†Ô∏è No se configur√≥ API key. Solo funcionar√° el modo mock.\")\n",
    "else:\n",
    "    logger.info(f\"‚úÖ Configuraci√≥n completa: {provider} - {MODEL_NAME}\")\n",
    "\n",
    "print(f\"\\nModelo: {MODEL_NAME}\")\n",
    "print(f\"Proveedor: {provider}\")\n",
    "print(f\"API Key configurada: {'S√≠ ‚úì' if API_KEY else 'No (solo modo mock)'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_section",
   "metadata": {},
   "source": [
    "## 4. Cargar Dataset de Goodreads\n",
    "\n",
    "Carga el archivo CSV y valida su estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "load_data_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: ‚úì Dataset cargado: 10000 registros, 8 columnas\n",
      "INFO: ‚úì Todas las columnas esperadas est√°n presentes\n",
      "INFO: ‚úì Todas las columnas esperadas est√°n presentes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "INFORMACI√ìN DEL DATASET\n",
      "============================================================\n",
      "Registros: 10,000\n",
      "Columnas: Unnamed: 0, Book, Author, Description, Genres, Avg_Rating, Num_Ratings, URL\n",
      "\n",
      "Primeros registros:\n",
      "                                                          Book        Author  Avg_Rating\n",
      "0                                        To Kill a Mockingbird    Harper Lee        4.27\n",
      "1  Harry Potter and the Philosopher‚Äôs Stone (Harry Potter, #1)  J.K. Rowling        4.47\n",
      "2                                          Pride and Prejudice   Jane Austen        4.28\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_and_validate_dataset(csv_path='goodreads_data.csv'):\n",
    "    \"\"\"Carga y valida el dataset de Goodreads\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        logger.info(f\"‚úì Dataset cargado: {len(df)} registros, {len(df.columns)} columnas\")\n",
    "        \n",
    "        # Validar columnas esperadas\n",
    "        expected_cols = ['Book', 'Author', 'Genres', 'Description']\n",
    "        missing = [col for col in expected_cols if col not in df.columns]\n",
    "        \n",
    "        if missing:\n",
    "            logger.warning(f\"‚ö†Ô∏è Columnas esperadas pero no encontradas: {missing}\")\n",
    "        else:\n",
    "            logger.info(\"‚úì Todas las columnas esperadas est√°n presentes\")\n",
    "        \n",
    "        # Mostrar informaci√≥n b√°sica\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"INFORMACI√ìN DEL DATASET\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Registros: {len(df):,}\")\n",
    "        print(f\"Columnas: {', '.join(df.columns.tolist())}\")\n",
    "        print(f\"\\nPrimeros registros:\")\n",
    "        print(df.head(3)[['Book', 'Author', 'Avg_Rating']].to_string())\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"‚ùå Archivo no encontrado: {csv_path}\")\n",
    "        logger.info(\"Intentando buscar en subdirectorios...\")\n",
    "        # Buscar en subdirectorios comunes\n",
    "        for path in ['./TP03/goodreads_data.csv', './TPv02/goodreads_data.csv']:\n",
    "            if Path(path).exists():\n",
    "                logger.info(f\"‚úì Encontrado en: {path}\")\n",
    "                return load_and_validate_dataset(path)\n",
    "        logger.error(\"‚ùå No se pudo encontrar goodreads_data.csv\")\n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error al cargar dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "# Cargar el dataset\n",
    "df = load_and_validate_dataset()\n",
    "\n",
    "if df is None:\n",
    "    print(\"\\n‚ö†Ô∏è ADVERTENCIA: Dataset no cargado. Las funciones estar√°n limitadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generate_text_section",
   "metadata": {},
   "source": [
    "## 5. Implementaci√≥n de la Funci√≥n de Generaci√≥n de Texto (LLM)\n",
    "\n",
    "Esta funci√≥n conecta con la API del proveedor seleccionado (Gemini o OpenAI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "generate_text_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funci√≥n generate_text() implementada\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt, mock=False, temperature=0.7, max_tokens=500):\n",
    "    \"\"\"\n",
    "    Genera texto usando el LLM configurado.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): El prompt a enviar al LLM\n",
    "        mock (bool): Si True, devuelve respuesta simulada\n",
    "        temperature (float): Temperatura para la generaci√≥n (0-1)\n",
    "        max_tokens (int): M√°ximo de tokens a generar\n",
    "    \n",
    "    Returns:\n",
    "        str: Respuesta del LLM o respuesta mock\n",
    "    \"\"\"\n",
    "    if mock:\n",
    "        logger.info(\"üé≠ Modo MOCK activado - generando respuesta simulada\")\n",
    "        # Respuestas simuladas seg√∫n el tipo de prompt\n",
    "        if \"is_relevant\" in prompt.lower():\n",
    "            return json.dumps({\n",
    "                \"is_relevant\": \"yes\",\n",
    "                \"explanation\": \"El prompt menciona recomendaci√≥n de libros, lo cual es relevante para el sistema.\"\n",
    "            })\n",
    "        else:\n",
    "            return json.dumps({\n",
    "                \"improved_prompt\": \"Recomi√©ndame 10 libros del g√©nero fantas√≠a contempor√°nea, publicados despu√©s de 2010, con rating promedio superior a 4.0 y al menos 1000 valoraciones.\",\n",
    "                \"notes\": [\n",
    "                    \"Se a√±adi√≥ especificaci√≥n de cantidad (10 libros)\",\n",
    "                    \"Se incluy√≥ filtro temporal (despu√©s de 2010)\",\n",
    "                    \"Se agregaron filtros de calidad (rating > 4.0, votos > 1000)\"\n",
    "                ]\n",
    "            })\n",
    "    \n",
    "    if not API_KEY:\n",
    "        raise ValueError(\"API_KEY no configurada. Usa mock=True para modo de prueba.\")\n",
    "    \n",
    "    try:\n",
    "        if provider == 'gemini':\n",
    "            import google.generativeai as genai\n",
    "            \n",
    "            genai.configure(api_key=API_KEY)\n",
    "            model = genai.GenerativeModel(MODEL_NAME)\n",
    "            \n",
    "            generation_config = {\n",
    "                \"temperature\": temperature,\n",
    "                \"max_output_tokens\": max_tokens,\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"üì° Llamando a Gemini ({MODEL_NAME})...\")\n",
    "            response = model.generate_content(\n",
    "                prompt,\n",
    "                generation_config=generation_config\n",
    "            )\n",
    "            \n",
    "            result = response.text\n",
    "            logger.info(f\"‚úì Respuesta recibida ({len(result)} caracteres)\")\n",
    "            return result\n",
    "        \n",
    "        elif provider == 'openai':\n",
    "            import openai\n",
    "            \n",
    "            openai.api_key = API_KEY\n",
    "            \n",
    "            logger.info(f\"üì° Llamando a OpenAI ({MODEL_NAME})...\")\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Eres un asistente experto en sistemas de recomendaci√≥n de libros.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "            \n",
    "            result = response.choices[0].message.content\n",
    "            logger.info(f\"‚úì Respuesta recibida ({len(result)} caracteres)\")\n",
    "            return result\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Proveedor no soportado: {provider}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error al generar texto: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"‚úÖ Funci√≥n generate_text() implementada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b520796",
   "metadata": {},
   "source": [
    "## 6. Heur√≠stica Local para Evaluar Pertinencia\n",
    "\n",
    "Evaluaci√≥n r√°pida (sin consumir API) basada en palabras clave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "395c4239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funciones de evaluaci√≥n de pertinencia implementadas\n"
     ]
    }
   ],
   "source": [
    "RELEVANT_KEYWORDS = [\n",
    "    'recommend', 'recomendar', 'sugerir', 'suggest',\n",
    "    'book', 'libro', 'novel', 'novela',\n",
    "    'fiction', 'ficci√≥n',\n",
    "    'recommendation', 'recomendaci√≥n',\n",
    "    'genre', 'g√©nero', 'genero',\n",
    "    'find', 'buscar', 'search',\n",
    "    'similar', 'parecido', 'like',\n",
    "    'read', 'leer', 'reading'\n",
    "]\n",
    "\n",
    "def heuristic_relevance_check(prompt):\n",
    "    \"\"\"\n",
    "    Evaluaci√≥n heur√≠stica r√°pida de pertinencia.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (is_relevant: bool, score: int)\n",
    "    \"\"\"\n",
    "    p = prompt.lower()\n",
    "    score = sum(1 for kw in RELEVANT_KEYWORDS if kw in p)\n",
    "    is_relevant = score >= 1\n",
    "    \n",
    "    logger.debug(f\"Heur√≠stica: score={score}, relevante={is_relevant}\")\n",
    "    return is_relevant, score\n",
    "\n",
    "\n",
    "def extract_json_from_text(text):\n",
    "    \"\"\"\n",
    "    Extrae el primer objeto JSON v√°lido del texto.\n",
    "    Correcci√≥n del regex defectuoso en la versi√≥n original.\n",
    "    \"\"\"\n",
    "    # Intentar con regex simple primero\n",
    "    patterns = [\n",
    "        r'\\{[^{}]*\\}',  # JSON simple de una l√≠nea\n",
    "        r'\\{.*?\\}',      # JSON multil√≠nea (non-greedy)\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        matches = re.finditer(pattern, text, flags=re.DOTALL)\n",
    "        for match in matches:\n",
    "            try:\n",
    "                return json.loads(match.group(0))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    \n",
    "    # Si no se pudo extraer JSON, crear objeto b√°sico\n",
    "    logger.debug(\"No se pudo extraer JSON v√°lido, creando objeto b√°sico\")\n",
    "    if 'yes' in text.lower() or 's√≠' in text.lower():\n",
    "        return {'is_relevant': 'yes', 'explanation': text.strip()}\n",
    "    else:\n",
    "        return {'is_relevant': 'no', 'explanation': text.strip()}\n",
    "\n",
    "\n",
    "def analyze_prompt_relevance(prompt, df=None, use_llm=True, mock=False):\n",
    "    \"\"\"\n",
    "    Analiza si un prompt es relevante para el sistema de recomendaci√≥n.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (is_relevant: bool, reason: str, llm_output: str or None)\n",
    "    \"\"\"\n",
    "    logger.info(f\"Analizando pertinencia del prompt: '{prompt[:50]}...'\")\n",
    "    \n",
    "    # Heur√≠stica r√°pida\n",
    "    relevance, score = heuristic_relevance_check(prompt)\n",
    "    reason_parts = [f'heuristic_score={score}']\n",
    "    llm_out = None\n",
    "    \n",
    "    if use_llm:\n",
    "        # Construir prompt para LLM\n",
    "        llm_prompt = f\"\"\"Eres un clasificador experto. Analiza si el siguiente prompt es relevante para un sistema de recomendaci√≥n de libros de ficci√≥n:\n",
    "\n",
    "PROMPT DEL USUARIO:\n",
    "{prompt}\n",
    "\n",
    "Responde √öNICAMENTE en formato JSON con estos campos:\n",
    "{{\n",
    "  \"is_relevant\": \"yes\" o \"no\",\n",
    "  \"explanation\": \"1-2 frases explicando tu decisi√≥n\"\n",
    "}}\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            llm_out = generate_text(llm_prompt, mock=mock)\n",
    "            j = extract_json_from_text(llm_out)\n",
    "            \n",
    "            is_rel = str(j.get('is_relevant', 'no')).lower().startswith('y')\n",
    "            reason_parts.append('llm_eval=' + ('yes' if is_rel else 'no'))\n",
    "            \n",
    "            explanation = j.get('explanation', '')\n",
    "            logger.info(f\"LLM evaluaci√≥n: {'relevante' if is_rel else 'no relevante'}\")\n",
    "            \n",
    "            return is_rel, '; '.join(reason_parts + [explanation]), llm_out\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error en evaluaci√≥n LLM: {e}\")\n",
    "            reason_parts.append(f'llm_error={type(e).__name__}')\n",
    "    \n",
    "    return relevance, '; '.join(reason_parts), llm_out\n",
    "\n",
    "print(\"‚úÖ Funciones de evaluaci√≥n de pertinencia implementadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681c00f7",
   "metadata": {},
   "source": [
    "## 7. Mejora Inteligente del Prompt\n",
    "\n",
    "La funci√≥n `improve_prompt` **busca autom√°ticamente** los libros mencionados en el dataset de Goodreads y extrae sus datos:\n",
    "\n",
    "**Funcionalidad autom√°tica:**\n",
    "- üîç Detecta libros mencionados en el prompt (ej. \"similar a '1984'\")\n",
    "- üìö Busca el libro en el dataset de Goodreads\n",
    "- üìä **Extrae autom√°ticamente**: autor, g√©neros, rating, n√∫mero de valoraciones, a√±o\n",
    "- ‚ú® Genera prompt mejorado con filtros basados en datos reales del dataset\n",
    "\n",
    "**No necesitas ingresar manualmente** g√©nero, autor, etc. - el sistema los obtiene autom√°ticamente del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1580ff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funciones de mejora de prompt implementadas\n",
      "üí° El sistema ahora busca autom√°ticamente libros en el dataset de Goodreads\n",
      "   y extrae: t√≠tulo, autor, g√©neros, rating, valoraciones, a√±o\n",
      "üîß ACTUALIZADO: Ahora detecta comillas tipogr√°ficas (Unicode) y comillas rectas\n",
      "   Soporta: comillas simples rectas ('), dobles rectas (\"), y comillas tipogr√°ficas\n"
     ]
    }
   ],
   "source": [
    "def summarize_df_columns(df, max_cols=15):\n",
    "    \"\"\"Resume las columnas del dataframe.\"\"\"\n",
    "    if df is None:\n",
    "        return 'Dataset no cargado'\n",
    "    cols = list(df.columns)[:max_cols]\n",
    "    result = ', '.join(cols)\n",
    "    if len(df.columns) > max_cols:\n",
    "        result += f' ... (+{len(df.columns) - max_cols} m√°s)'\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_book_reference(prompt):\n",
    "    \"\"\"Extrae menciones a libros espec√≠ficos del prompt.\"\"\"\n",
    "    # Patrones que aceptan comillas rectas (' \") y comillas tipogr√°ficas (Unicode)\n",
    "    # Usando c√≥digos Unicode expl√≠citos para evitar problemas de sintaxis\n",
    "    patterns = [\n",
    "        r\"similar(?:\\s+a)?\\s+['\\\"\\u2018\\u2019\\u201C\\u201D]([^'\\\"\\u2018\\u2019\\u201C\\u201D]+)['\\\"\\u2018\\u2019\\u201C\\u201D]\",  # similar a \"titulo\"\n",
    "        r\"como\\s+['\\\"\\u2018\\u2019\\u201C\\u201D]([^'\\\"\\u2018\\u2019\\u201C\\u201D]+)['\\\"\\u2018\\u2019\\u201C\\u201D]\",  # como \"titulo\"\n",
    "        r\"parecido\\s+a\\s+['\\\"\\u2018\\u2019\\u201C\\u201D]([^'\\\"\\u2018\\u2019\\u201C\\u201D]+)['\\\"\\u2018\\u2019\\u201C\\u201D]\",  # parecido a \"titulo\"\n",
    "        r\"['\\\"\\u2018\\u2019\\u201C\\u201D]([^'\\\"\\u2018\\u2019\\u201C\\u201D]{3,})['\\\"\\u2018\\u2019\\u201C\\u201D]\",  # cualquier \"Titulo\" (m√≠nimo 3 caracteres)\n",
    "    ]\n",
    "    \n",
    "    for pat in patterns:\n",
    "        m = re.search(pat, prompt, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            candidate = m.group(1).strip()\n",
    "            if len(candidate) > 2:\n",
    "                logger.debug(f\"Libro detectado: '{candidate}'\")\n",
    "                return candidate\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def search_book_in_df(df, book_title):\n",
    "    \"\"\"Busca un libro en el dataframe.\"\"\"\n",
    "    if df is None or book_title is None:\n",
    "        return None\n",
    "    \n",
    "    # Buscar columna de t√≠tulo\n",
    "    title_col = None\n",
    "    for col in df.columns:\n",
    "        if col.lower() in ['title', 'book', 'name', 'titulo']:\n",
    "            title_col = col\n",
    "            break\n",
    "    \n",
    "    if title_col is None:\n",
    "        logger.warning(\"No se encontr√≥ columna de t√≠tulo en el dataset\")\n",
    "        return None\n",
    "    \n",
    "    # B√∫squeda case-insensitive\n",
    "    bt_lower = book_title.lower()\n",
    "    matches = df[df[title_col].astype(str).str.lower().str.contains(bt_lower, na=False, regex=False)]\n",
    "    \n",
    "    if len(matches) > 0:\n",
    "        logger.info(f\"‚úì Libro encontrado: {matches.iloc[0][title_col]}\")\n",
    "        return matches.iloc[0]\n",
    "    \n",
    "    logger.debug(f\"Libro '{book_title}' no encontrado en el dataset\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def improve_prompt(prompt, df=None, use_llm=False, mock=False):\n",
    "    \"\"\"\n",
    "    Mejora el prompt usando an√°lisis inteligente del dataset.\n",
    "    \n",
    "    Estrategia:\n",
    "    1. Detectar si menciona un libro espec√≠fico\n",
    "    2. Buscar ese libro en el dataset de Goodreads\n",
    "    3. Extraer metadata autom√°ticamente (g√©nero, autor, rating, etc.)\n",
    "    4. Construir prompt mejorado con filtros espec√≠ficos basados en datos reales\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (improved_prompt: str, notes: list)\n",
    "    \"\"\"\n",
    "    logger.info(\"Mejorando prompt...\")\n",
    "    notes = []\n",
    "    \n",
    "    # Informaci√≥n sobre columnas disponibles\n",
    "    cols_summary = summarize_df_columns(df)\n",
    "    notes.append(f'Columnas disponibles: {cols_summary}')\n",
    "    \n",
    "    # Intentar detectar libro de referencia\n",
    "    book_ref = extract_book_reference(prompt)\n",
    "    \n",
    "    if book_ref and df is not None:\n",
    "        notes.append(f'üìö Libro mencionado en el prompt: \"{book_ref}\"')\n",
    "        \n",
    "        # Buscar en el dataset de Goodreads\n",
    "        found_row = search_book_in_df(df, book_ref)\n",
    "        \n",
    "        if found_row is not None:\n",
    "            # ‚úÖ LIBRO ENCONTRADO - Extraer datos autom√°ticamente del dataset\n",
    "            notes.append(f'‚úÖ Libro encontrado en el dataset de Goodreads')\n",
    "            improved_parts = []\n",
    "            metadata_info = []\n",
    "            \n",
    "            # T√≠tulo exacto\n",
    "            if 'Book' in found_row:\n",
    "                title = found_row['Book']\n",
    "                improved_parts.append(f'Recomendar libros similares a \"{title}\"')\n",
    "                metadata_info.append(f'üìñ T√≠tulo: {title}')\n",
    "            \n",
    "            # Autor (extra√≠do del dataset)\n",
    "            if 'Author' in found_row and pd.notna(found_row['Author']):\n",
    "                author = found_row['Author']\n",
    "                metadata_info.append(f'‚úçÔ∏è Autor: {author}')\n",
    "                notes.append(f'Autor del libro de referencia: {author}')\n",
    "            \n",
    "            # G√©neros (extra√≠dos del dataset)\n",
    "            if 'Genres' in found_row and pd.notna(found_row['Genres']):\n",
    "                genres = str(found_row['Genres'])\n",
    "                improved_parts.append(f'del g√©nero: {genres[:100]}')\n",
    "                metadata_info.append(f'üé≠ G√©neros: {genres[:80]}...' if len(genres) > 80 else f'üé≠ G√©neros: {genres}')\n",
    "                notes.append(f'G√©neros autom√°ticamente detectados: {genres[:60]}...' if len(genres) > 60 else f'G√©neros: {genres}')\n",
    "            \n",
    "            # Rating (extra√≠do del dataset)\n",
    "            if 'Avg_Rating' in found_row and pd.notna(found_row['Avg_Rating']):\n",
    "                rating = float(found_row['Avg_Rating'])\n",
    "                min_rating = max(3.5, rating - 0.5)\n",
    "                improved_parts.append(f'con rating m√≠nimo: {min_rating:.1f}')\n",
    "                metadata_info.append(f'‚≠ê Rating del libro de referencia: {rating:.2f}')\n",
    "                notes.append(f'Rating autom√°ticamente detectado: {rating:.2f} ‚Üí filtro sugerido: m√≠nimo {min_rating:.1f}')\n",
    "            \n",
    "            # N√∫mero de valoraciones (extra√≠do del dataset)\n",
    "            if 'Num_Ratings' in found_row and pd.notna(found_row['Num_Ratings']):\n",
    "                num_ratings_raw = found_row['Num_Ratings']\n",
    "                num_ratings_converted = pd.to_numeric(num_ratings_raw, errors='coerce')\n",
    "                if pd.notna(num_ratings_converted):\n",
    "                    num_ratings = int(num_ratings_converted)\n",
    "                    min_votes = max(100, num_ratings // 20)\n",
    "                    improved_parts.append(f'y al menos {min_votes:,} valoraciones')\n",
    "                    metadata_info.append(f'üë• Valoraciones del libro de referencia: {num_ratings:,}')\n",
    "                    notes.append(f'Valoraciones autom√°ticamente detectadas: {num_ratings:,} ‚Üí filtro sugerido: m√≠nimo {min_votes:,}')\n",
    "            \n",
    "            # A√±o de publicaci√≥n (si est√° disponible)\n",
    "            if 'Year' in found_row and pd.notna(found_row['Year']):\n",
    "                year = int(found_row['Year'])\n",
    "                metadata_info.append(f'üìÖ A√±o: {year}')\n",
    "                notes.append(f'A√±o de publicaci√≥n: {year}')\n",
    "            \n",
    "            improved_parts.append('| Limitar resultados a top 10')\n",
    "            \n",
    "            improved = ' '.join(improved_parts)\n",
    "            \n",
    "            # Agregar resumen de metadata extra√≠da\n",
    "            notes.append('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ')\n",
    "            notes.append('üìä METADATA EXTRA√çDA DEL DATASET DE GOODREADS:')\n",
    "            notes.extend(metadata_info)\n",
    "            notes.append('‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ')\n",
    "            notes.append('‚úÖ Prompt mejorado autom√°ticamente con datos reales del dataset')\n",
    "        \n",
    "        else:\n",
    "            # ‚ùå Libro no encontrado en el dataset\n",
    "            improved = f'{prompt} | Nota: El libro \"{book_ref}\" no se encontr√≥ en el dataset de Goodreads. Usar filtros gen√©ricos: g√©nero espec√≠fico, rating>4.0, votos>500, limitar a 10 resultados.'\n",
    "            notes.append(f'‚ö†Ô∏è Libro \"{book_ref}\" NO encontrado en el dataset')\n",
    "            notes.append(f'üí° Sugerencia: Verifica el t√≠tulo exacto o prueba con otro libro')\n",
    "    \n",
    "    else:\n",
    "        # No se detect√≥ libro espec√≠fico: mejora gen√©rica\n",
    "        improved = f\"{prompt} | Sugerencias: especificar un libro de ejemplo (ej. 'similar a \\\"1984\\\"'), g√©nero, rango de rating (ej. >4.0), votos m√≠nimos (ej. >500), n√∫mero de resultados (ej. top 10).\"\n",
    "        notes.append('‚ÑπÔ∏è No se detect√≥ menci√≥n a un libro espec√≠fico en el prompt')\n",
    "        notes.append('üí° Sugerencia: Menciona un libro entre comillas para b√∫squeda autom√°tica en Goodreads')\n",
    "    \n",
    "    logger.info(\"‚úì Prompt mejorado generado\")\n",
    "    return improved, notes\n",
    "\n",
    "print(\"‚úÖ Funciones de mejora de prompt implementadas\")\n",
    "print(\"üí° El sistema ahora busca autom√°ticamente libros en el dataset de Goodreads\")\n",
    "print(\"   y extrae: t√≠tulo, autor, g√©neros, rating, valoraciones, a√±o\")\n",
    "print(\"üîß ACTUALIZADO: Ahora detecta comillas tipogr√°ficas (Unicode) y comillas rectas\")\n",
    "print(\"   Soporta: comillas simples rectas ('), dobles rectas (\\\"), y comillas tipogr√°ficas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ecf5f",
   "metadata": {},
   "source": [
    "## 8. Uso: Evaluar y Mejorar un Prompt\n",
    "\n",
    "Define tu prompt en la variable `PROMPT` y ejecuta para ver:\n",
    "- ‚úÖ Evaluaci√≥n de pertinencia\n",
    "- üîç **B√∫squeda autom√°tica** del libro mencionado en Goodreads\n",
    "- üìä **Extracci√≥n autom√°tica** de metadata (autor, g√©nero, rating, etc.)\n",
    "- ‚ú® Versi√≥n mejorada del prompt con datos reales\n",
    "- üìù Notas explicativas detalladas\n",
    "\n",
    "**C√≥mo funciona la b√∫squeda autom√°tica:**\n",
    "1. Menciona un libro entre comillas en tu prompt: `\"similar a '1984'\"`\n",
    "2. El sistema lo busca autom√°ticamente en el dataset de Goodreads\n",
    "3. Extrae: autor, g√©neros, rating, valoraciones, a√±o\n",
    "4. Genera un prompt mejorado con esos datos reales\n",
    "\n",
    "**No necesitas ingresar manualmente** ning√∫n dato - el sistema los encuentra autom√°ticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21f0108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Analizando pertinencia del prompt: 'Recomi√©ndame libros similares a '1984'...'\n",
      "INFO: Mejorando prompt...\n",
      "INFO: Mejorando prompt...\n",
      "INFO: ‚úì Libro encontrado: 1984\n",
      "INFO: ‚úì Prompt mejorado generado\n",
      "INFO: ‚úì Libro encontrado: 1984\n",
      "INFO: ‚úì Prompt mejorado generado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "AN√ÅLISIS DE PROMPT\n",
      "======================================================================\n",
      "\n",
      "Prompt original:\n",
      "  \"Recomi√©ndame libros similares a '1984'\"\n",
      "\n",
      "üí° El sistema buscar√° autom√°ticamente '1984' en Goodreads\n",
      "   y extraer√°: autor, g√©neros, rating, valoraciones, a√±o\n",
      "\n",
      "üîç Evaluando pertinencia...\n",
      "\n",
      "======================================================================\n",
      "RESULTADO DE PERTINENCIA\n",
      "======================================================================\n",
      "  ¬øEs pertinente?: ‚úÖ S√ç\n",
      "  Raz√≥n: heuristic_score=2\n",
      "\n",
      "======================================================================\n",
      "üîß Mejorando prompt con b√∫squeda autom√°tica en Goodreads...\n",
      "\n",
      "======================================================================\n",
      "PROMPT MEJORADO\n",
      "======================================================================\n",
      "\n",
      "Recomendar libros similares a \"1984\" del g√©nero: ['Classics', 'Fiction', 'Science Fiction', 'Dystopia', 'Literature', 'Novels', 'Politics'] con rating m√≠nimo: 3.7 | Limitar resultados a top 10\n",
      "\n",
      "======================================================================\n",
      "METADATA EXTRA√çDA Y NOTAS\n",
      "======================================================================\n",
      "  Columnas disponibles: Unnamed: 0, Book, Author, Description, Genres, Avg_Rating, Num_Ratings, URL\n",
      "  üìö Libro mencionado en el prompt: \"1984\"\n",
      "  ‚úÖ Libro encontrado en el dataset de Goodreads\n",
      "  Autor del libro de referencia: George Orwell\n",
      "  G√©neros autom√°ticamente detectados: ['Classics', 'Fiction', 'Science Fiction', 'Dystopia', 'Lite...\n",
      "  Rating autom√°ticamente detectado: 4.19 ‚Üí filtro sugerido: m√≠nimo 3.7\n",
      "  ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "  üìä METADATA EXTRA√çDA DEL DATASET DE GOODREADS:\n",
      "  üìñ T√≠tulo: 1984\n",
      "  ‚úçÔ∏è Autor: George Orwell\n",
      "  üé≠ G√©neros: ['Classics', 'Fiction', 'Science Fiction', 'Dystopia', 'Literature', 'Novels', '...\n",
      "  ‚≠ê Rating del libro de referencia: 4.19\n",
      "  ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "  ‚úÖ Prompt mejorado autom√°ticamente con datos reales del dataset\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CONFIGURACI√ìN - Edita aqu√≠ tu prompt\n",
    "# ========================================\n",
    "\n",
    "# Simplemente menciona un libro entre comillas y el sistema buscar√° autom√°ticamente\n",
    "# todos sus datos (autor, g√©nero, rating, etc.) en el dataset de Goodreads\n",
    "PROMPT = \"Recomi√©ndame libros similares a '1984'\"\n",
    "\n",
    "# Opciones de ejecuci√≥n\n",
    "use_llm = False   # True para usar LLM real (requiere API_KEY configurada)\n",
    "mock = True       # True para modo de prueba sin consumir API\n",
    "\n",
    "# ========================================\n",
    "# EJECUCI√ìN\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AN√ÅLISIS DE PROMPT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nPrompt original:\\n  \\\"{PROMPT}\\\"\\n\")\n",
    "print(\"üí° El sistema buscar√° autom√°ticamente '1984' en Goodreads\")\n",
    "print(\"   y extraer√°: autor, g√©neros, rating, valoraciones, a√±o\\n\")\n",
    "\n",
    "# 1. Evaluar pertinencia\n",
    "print(\"üîç Evaluando pertinencia...\")\n",
    "is_rel, reason, llm_out = analyze_prompt_relevance(\n",
    "    PROMPT, \n",
    "    df=df if df is not None else None, \n",
    "    use_llm=use_llm, \n",
    "    mock=mock\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"RESULTADO DE PERTINENCIA\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  ¬øEs pertinente?: {'‚úÖ S√ç' if is_rel else '‚ùå NO'}\")\n",
    "print(f\"  Raz√≥n: {reason}\")\n",
    "\n",
    "if llm_out and use_llm:\n",
    "    print(f\"\\n  Respuesta del LLM:\\n  {llm_out}\")\n",
    "\n",
    "# 2. Mejorar prompt (b√∫squeda autom√°tica en Goodreads)\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üîß Mejorando prompt con b√∫squeda autom√°tica en Goodreads...\")\n",
    "improved, notes = improve_prompt(\n",
    "    PROMPT, \n",
    "    df=df if df is not None else None, \n",
    "    use_llm=use_llm, \n",
    "    mock=mock\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PROMPT MEJORADO\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\n{improved}\\n\")\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"METADATA EXTRA√çDA Y NOTAS\")\n",
    "print(f\"{'='*70}\")\n",
    "for i, note in enumerate(notes, 1):\n",
    "    print(f\"  {note}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70ea9643",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mStop\u001b[49m \n",
      "\u001b[31mNameError\u001b[39m: name 'Stop' is not defined"
     ]
    }
   ],
   "source": [
    "Stop "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "examples_section",
   "metadata": {},
   "source": [
    "## 9. Ejemplos Adicionales\n",
    "\n",
    "Prueba con diferentes tipos de prompts. Los que mencionan libros espec√≠ficos entre comillas activar√°n la **b√∫squeda autom√°tica** en Goodreads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "examples_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Analizando pertinencia del prompt: 'libros de fantas√≠a...'\n",
      "INFO: Mejorando prompt...\n",
      "INFO: ‚úì Prompt mejorado generado\n",
      "INFO: Analizando pertinencia del prompt: 'algo como 'Harry Potter'...'\n",
      "INFO: Mejorando prompt...\n",
      "INFO: ‚úì Libro encontrado: Harry Potter and the Philosopher‚Äôs Stone (Harry Potter, #1)\n",
      "INFO: ‚úì Prompt mejorado generado\n",
      "INFO: Analizando pertinencia del prompt: 'similar a 'The Hunger Games'...'\n",
      "INFO: Mejorando prompt...\n",
      "INFO: ‚úì Libro encontrado: The Hunger Games (The Hunger Games, #1)\n",
      "INFO: ‚úì Prompt mejorado generado\n",
      "INFO: Mejorando prompt...\n",
      "INFO: ‚úì Prompt mejorado generado\n",
      "INFO: Analizando pertinencia del prompt: 'algo como 'Harry Potter'...'\n",
      "INFO: Mejorando prompt...\n",
      "INFO: ‚úì Libro encontrado: Harry Potter and the Philosopher‚Äôs Stone (Harry Potter, #1)\n",
      "INFO: ‚úì Prompt mejorado generado\n",
      "INFO: Analizando pertinencia del prompt: 'similar a 'The Hunger Games'...'\n",
      "INFO: Mejorando prompt...\n",
      "INFO: ‚úì Libro encontrado: The Hunger Games (The Hunger Games, #1)\n",
      "INFO: ‚úì Prompt mejorado generado\n",
      "INFO: Analizando pertinencia del prompt: 'quiero leer ciencia ficci√≥n dist√≥pica...'\n",
      "INFO: Mejorando prompt...\n",
      "INFO: ‚úì Prompt mejorado generado\n",
      "INFO: Analizando pertinencia del prompt: 'recomi√©ndame algo parecido a 'To Kill a Mockingbir...'\n",
      "INFO: Mejorando prompt...\n",
      "INFO: Analizando pertinencia del prompt: 'quiero leer ciencia ficci√≥n dist√≥pica...'\n",
      "INFO: Mejorando prompt...\n",
      "INFO: ‚úì Prompt mejorado generado\n",
      "INFO: Analizando pertinencia del prompt: 'recomi√©ndame algo parecido a 'To Kill a Mockingbir...'\n",
      "INFO: Mejorando prompt...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EJEMPLOS DE MEJORA DE PROMPTS\n",
      "======================================================================\n",
      "\n",
      "üí° Los prompts con libros entre comillas activar√°n b√∫squeda autom√°tica\n",
      "   en el dataset de Goodreads para extraer metadata real\n",
      "\n",
      "\n",
      "1. ORIGINAL: \"libros de fantas√≠a\"\n",
      "   Pertinente: ‚úÖ\n",
      "   MEJORADO: libros de fantas√≠a | Sugerencias: especificar un libro de ejemplo (ej. 'similar a \"1984\"'), g√©nero, rango de rating (ej. >4.0), votos m√≠nimos (ej. >500), n√∫mero de resultados (ej. ...\n",
      "\n",
      "\n",
      "2. ORIGINAL: \"algo como 'Harry Potter'\"\n",
      "   Pertinente: ‚ùå\n",
      "   MEJORADO: Recomendar libros similares a \"Harry Potter and the Philosopher‚Äôs Stone (Harry Potter, #1)\" del g√©nero: ['Fantasy', 'Fiction', 'Young Adult', 'Magic', 'Childrens', 'Middle Grade', ...\n",
      "   üéØ Libro encontrado - metadata extra√≠da autom√°ticamente\n",
      "\n",
      "\n",
      "3. ORIGINAL: \"similar a 'The Hunger Games'\"\n",
      "   Pertinente: ‚úÖ\n",
      "   MEJORADO: Recomendar libros similares a \"The Hunger Games (The Hunger Games, #1)\" del g√©nero: ['Young Adult', 'Fiction', 'Dystopia', 'Fantasy', 'Science Fiction', 'Romance', 'Adventure'] con...\n",
      "   üéØ Libro encontrado - metadata extra√≠da autom√°ticamente\n",
      "\n",
      "\n",
      "4. ORIGINAL: \"quiero leer ciencia ficci√≥n dist√≥pica\"\n",
      "   Pertinente: ‚úÖ\n",
      "   MEJORADO: quiero leer ciencia ficci√≥n dist√≥pica | Sugerencias: especificar un libro de ejemplo (ej. 'similar a \"1984\"'), g√©nero, rango de rating (ej. >4.0), votos m√≠nimos (ej. >500), n√∫mero ...\n",
      "\n",
      "\n",
      "5. ORIGINAL: \"recomi√©ndame algo parecido a 'To Kill a Mockingbird'\"\n",
      "   Pertinente: ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: ‚úì Libro encontrado: To Kill a Mockingbird\n",
      "INFO: ‚úì Prompt mejorado generado\n",
      "INFO: ‚úì Prompt mejorado generado\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MEJORADO: Recomendar libros similares a \"To Kill a Mockingbird\" del g√©nero: ['Classics', 'Fiction', 'Historical Fiction', 'School', 'Literature', 'Young Adult', 'Historical'] con rating m√≠ni...\n",
      "   üéØ Libro encontrado - metadata extra√≠da autom√°ticamente\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Ejemplos de prompts para probar\n",
    "# Los que tienen libros entre comillas activar√°n b√∫squeda autom√°tica en Goodreads\n",
    "ejemplos = [\n",
    "    \"libros de fantas√≠a\",  # Sin libro espec√≠fico - mejora gen√©rica\n",
    "    \"algo como 'Harry Potter'\",  # CON libro - busca autom√°ticamente en Goodreads\n",
    "    \"similar a 'The Hunger Games'\",  # CON libro - extrae metadata autom√°ticamente\n",
    "    \"quiero leer ciencia ficci√≥n dist√≥pica\",  # Sin libro espec√≠fico\n",
    "    \"recomi√©ndame algo parecido a 'To Kill a Mockingbird'\",  # CON libro - b√∫squeda autom√°tica\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EJEMPLOS DE MEJORA DE PROMPTS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüí° Los prompts con libros entre comillas activar√°n b√∫squeda autom√°tica\")\n",
    "print(\"   en el dataset de Goodreads para extraer metadata real\\n\")\n",
    "\n",
    "for i, ejemplo in enumerate(ejemplos, 1):\n",
    "    print(f\"\\n{i}. ORIGINAL: \\\"{ejemplo}\\\"\")\n",
    "    \n",
    "    # Evaluar\n",
    "    is_rel, _, _ = analyze_prompt_relevance(ejemplo, df=df, use_llm=False, mock=True)\n",
    "    print(f\"   Pertinente: {'‚úÖ' if is_rel else '‚ùå'}\")\n",
    "    \n",
    "    # Mejorar (con b√∫squeda autom√°tica si menciona libro)\n",
    "    improved, notes = improve_prompt(ejemplo, df=df, use_llm=False, mock=True)\n",
    "    print(f\"   MEJORADO: {improved[:180]}...\")\n",
    "    \n",
    "    # Mostrar si encontr√≥ libro autom√°ticamente\n",
    "    if any('encontrado en el dataset' in note for note in notes):\n",
    "        print(f\"   üéØ Libro encontrado - metadata extra√≠da autom√°ticamente\")\n",
    "    elif any('mencionado en el prompt' in note for note in notes):\n",
    "        print(f\"   ‚ö†Ô∏è Libro mencionado pero no encontrado en dataset\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stats_section",
   "metadata": {},
   "source": [
    "## 10. Estad√≠sticas del Dataset (Opcional)\n",
    "\n",
    "Explora el dataset para entender mejor qu√© filtros puedes usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stats_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ESTAD√çSTICAS DEL DATASET\n",
      "======================================================================\n",
      "\n",
      "üìä Informaci√≥n General:\n",
      "   Total de libros: 10,000\n",
      "   Columnas: 8\n",
      "\n",
      "‚≠ê Ratings:\n",
      "   Promedio: 4.07\n",
      "   M√≠nimo: 0.00\n",
      "   M√°ximo: 5.00\n",
      "   Mediana: 4.08\n",
      "\n",
      "üë• N√∫mero de Valoraciones:\n",
      "   Total: 453,789\n",
      "   Promedio por libro: 164\n",
      "   M√°ximo: 999\n",
      "\n",
      "üìö Top 5 Libros M√°s Valorados:\n",
      "   ‚Ä¢ Hometown Girl After All (Hometown, #2)\n",
      "     Kirsten Fullmer - ‚≠ê4.32 (999 votos)\n",
      "   ‚Ä¢ Hometown Girl After All (Hometown, #2)\n",
      "     Kirsten Fullmer - ‚≠ê4.32 (999 votos)\n",
      "   ‚Ä¢ Belonging (Temptation, #2)\n",
      "     Karen Ann Hopkins - ‚≠ê3.98 (998 votos)\n",
      "   ‚Ä¢ ÿ™ÿ¥Ÿä\n",
      "     ÿ£ÿ≠ŸÖÿØ ÿÆÿßŸÑÿØ ÿ™ŸàŸÅŸäŸÇ - ‚≠ê4.0 (998 votos)\n",
      "   ‚Ä¢ Living The Best Day Ever\n",
      "     Hendri Coetzee - ‚≠ê4.34 (997 votos)\n",
      "\n",
      "======================================================================\n",
      "\n",
      "   Mediana: 4.08\n",
      "\n",
      "üë• N√∫mero de Valoraciones:\n",
      "   Total: 453,789\n",
      "   Promedio por libro: 164\n",
      "   M√°ximo: 999\n",
      "\n",
      "üìö Top 5 Libros M√°s Valorados:\n",
      "   ‚Ä¢ Hometown Girl After All (Hometown, #2)\n",
      "     Kirsten Fullmer - ‚≠ê4.32 (999 votos)\n",
      "   ‚Ä¢ Hometown Girl After All (Hometown, #2)\n",
      "     Kirsten Fullmer - ‚≠ê4.32 (999 votos)\n",
      "   ‚Ä¢ Belonging (Temptation, #2)\n",
      "     Karen Ann Hopkins - ‚≠ê3.98 (998 votos)\n",
      "   ‚Ä¢ ÿ™ÿ¥Ÿä\n",
      "     ÿ£ÿ≠ŸÖÿØ ÿÆÿßŸÑÿØ ÿ™ŸàŸÅŸäŸÇ - ‚≠ê4.0 (998 votos)\n",
      "   ‚Ä¢ Living The Best Day Ever\n",
      "     Hendri Coetzee - ‚≠ê4.34 (997 votos)\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ESTAD√çSTICAS DEL DATASET\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nüìä Informaci√≥n General:\")\n",
    "    print(f\"   Total de libros: {len(df):,}\")\n",
    "    print(f\"   Columnas: {len(df.columns)}\")\n",
    "    \n",
    "    if 'Avg_Rating' in df.columns:\n",
    "        print(f\"\\n‚≠ê Ratings:\")\n",
    "        print(f\"   Promedio: {df['Avg_Rating'].mean():.2f}\")\n",
    "        print(f\"   M√≠nimo: {df['Avg_Rating'].min():.2f}\")\n",
    "        print(f\"   M√°ximo: {df['Avg_Rating'].max():.2f}\")\n",
    "        print(f\"   Mediana: {df['Avg_Rating'].median():.2f}\")\n",
    "    \n",
    "    if 'Num_Ratings' in df.columns:\n",
    "        # Convertir a num√©rico si es necesario\n",
    "        num_ratings = pd.to_numeric(df['Num_Ratings'], errors='coerce')\n",
    "        print(f\"\\nüë• N√∫mero de Valoraciones:\")\n",
    "        print(f\"   Total: {num_ratings.sum():,.0f}\")\n",
    "        print(f\"   Promedio por libro: {num_ratings.mean():.0f}\")\n",
    "        print(f\"   M√°ximo: {num_ratings.max():,.0f}\")\n",
    "    \n",
    "    print(f\"\\nüìö Top 5 Libros M√°s Valorados:\")\n",
    "    if 'Num_Ratings' in df.columns:\n",
    "        # Asegurar que Num_Ratings sea num√©rico para ordenar\n",
    "        df_sorted = df.copy()\n",
    "        df_sorted['Num_Ratings_numeric'] = pd.to_numeric(df_sorted['Num_Ratings'], errors='coerce')\n",
    "        top = df_sorted.nlargest(5, 'Num_Ratings_numeric')[['Book', 'Author', 'Avg_Rating', 'Num_Ratings']]\n",
    "        for idx, row in top.iterrows():\n",
    "            print(f\"   ‚Ä¢ {row['Book'][:50]}\")\n",
    "            num_votes = pd.to_numeric(row['Num_Ratings'], errors='coerce')\n",
    "            if pd.notna(num_votes):\n",
    "                print(f\"     {row['Author']} - ‚≠ê{row['Avg_Rating']} ({num_votes:,.0f} votos)\")\n",
    "            else:\n",
    "                print(f\"     {row['Author']} - ‚≠ê{row['Avg_Rating']} ({row['Num_Ratings']} votos)\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\\n\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Dataset no cargado - no se pueden mostrar estad√≠sticas\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
