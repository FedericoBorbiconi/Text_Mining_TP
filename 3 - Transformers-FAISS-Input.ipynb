{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d222ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FBorbiconi\\anaconda3\\envs\\text_mining\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libros despuÃ©s del filtrado: 43837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1370/1370 [38:15<00:00,  1.68s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (43837, 384)\n",
      "Total libros indexados: 43837\n",
      "âœ… Ãndice y metadata guardados\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "\n",
    "# 1. Cargar dataset\n",
    "df = pd.read_csv(\"fiction_books_clean.csv\")\n",
    "\n",
    "# 2. Eliminar libros sin descripciÃ³n (Reemplazar por la limpieza de Noe)\n",
    "df = df.dropna(subset=[\"description\"])\n",
    "df = df[df[\"description\"].str.strip() != \"\"]\n",
    "print(\"Libros despuÃ©s del filtrado:\", len(df))\n",
    "\n",
    "\n",
    "# 3. Generar embeddings\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=\"cpu\")\n",
    "\n",
    "# Convertimos todas las descripciones en embeddings\n",
    "embeddings = model.encode(\n",
    "    df[\"description\"].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32,\n",
    "    normalize_embeddings=True  # normaliza a norma 1 â†’ mÃ¡s fÃ¡cil similitud coseno\n",
    ")\n",
    "\n",
    "embeddings = np.array(embeddings).astype(\"float32\")\n",
    "print(\"Embeddings shape:\", embeddings.shape)  # (n_libros, 384)\n",
    "\n",
    "\n",
    "# 4. Crear Ã­ndice FAISS\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner Product (como coseno si estÃ¡ normalizado)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"Total libros indexados:\", index.ntotal)\n",
    "\n",
    "# 5. Guardar para usar luego\n",
    "faiss.write_index(index, \"libros_clean.index\")\n",
    "df.to_parquet(\"libros_clean_metadata.parquet\", engine=\"fastparquet\", index=False)\n",
    "\n",
    "print(\"âœ… Ãndice y metadata guardados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea372021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FBorbiconi\\anaconda3\\envs\\text_mining\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Your query was too short, to offer you better recomendations please answer a few more questions...\n",
      "\n",
      "\n",
      "âœ… Expanded query: A fantasy story set in small town, featuring adult characters, with a dark tone.\n",
      "\n",
      "\n",
      "Rank 1: Wildwood Imperium (Wildwood Chronicles #3) - Colin Meloy\n",
      "Score (similarity): 0.597\n",
      "Rating: 5.00\n",
      "DescripciÃ³n: A young girl's midnight sÃ©ance awakens a long-slumbering malevolent spirit.... A band of runaway orphans allies with an underground collective of saboteurs and plans a daring rescue of their friends, ...\n",
      "\n",
      "Rank 2: Winesburg, Ohio - Sherwood Anderson\n",
      "Score (similarity): 0.558\n",
      "Rating: 3.29\n",
      "DescripciÃ³n: A unified collection of short stories about life in a small town in the American Midwest....\n",
      "\n",
      "Rank 3: Sunshine sketches of a little town - Stephen Leacock\n",
      "Score (similarity): 0.557\n",
      "Rating: 5.00\n",
      "DescripciÃ³n: \"Set in the fictional landscape of Mariposa on the shores of Lake Wissanotti in Missinaba County, Leacock's Sunshine Sketches of A Little Town is an affectionate satire of small town life. This series...\n",
      "\n",
      "Rank 4: Noisy Outlaws, Unfriendly Blobs, and Some Other Things . . - Ted Thompson, Eli Horowitz, Lemony Snicket, Nick Hornsby, George Saunders\n",
      "Score (similarity): 0.551\n",
      "Rating: 3.50\n",
      "DescripciÃ³n: A collection of stories for wise young people and immature old people!A collection of stories for wise young people and immature old people, written by today's best authors spinning new tales. Each st...\n",
      "\n",
      "Rank 5: KÄmarÅ«pa kataikaá¸· - Charu Nivedita\n",
      "Score (similarity): 0.537\n",
      "Rating: 5.00\n",
      "DescripciÃ³n: Novel based on sex stories....\n"
     ]
    }
   ],
   "source": [
    "# Esto no es necesario si corriste celda anterior\n",
    "######\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=\"cpu\")\n",
    "######\n",
    "\n",
    "# Cargar lo guardado\n",
    "index = faiss.read_index(\"libros_clean.index\")\n",
    "df = pd.read_parquet(\"libros_clean_metadata.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "\n",
    "# Enriquecedor de query\n",
    "def build_expanded_query(query: str) -> str:\n",
    "    \"\"\"\n",
    "    If the query is short (<40 characters), ask for more details\n",
    "    and build an enriched query in English.\n",
    "    \"\"\"\n",
    "    if len(query.strip()) < 40:\n",
    "        print(\"âš ï¸ Your query was too short, to offer you better recomendations please answer a few more questions...\\n\")\n",
    "        \n",
    "        genre = input(\"ðŸ“š Which genre are you looking for? (e.g., romance, fantasy, mystery): \")\n",
    "        place = input(\"ðŸŒ Where should the story take place? (e.g., small town, big city, magical kingdom, outer space, historical setting): \")\n",
    "        characters = input(\"ðŸ‘¤ What kind of characters? (e.g., teenagers, heroes, families): \")\n",
    "        tone = input(\"ðŸŽ­ What tone do you prefer? (e.g., dramatic, funny, dark, hopeful): \")\n",
    "        \n",
    "        query_expanded = (\n",
    "            f\"A {genre} story set in {place}, featuring {characters} characters, with a {tone} tone.\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nâœ… Expanded query: {query_expanded}\\n\")\n",
    "        return query_expanded\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\nðŸ‘¤ User query: {query}\")\n",
    "\n",
    "    return query.strip()\n",
    "\n",
    "# Filtros de bÃºsqueda\n",
    "def ask_filters() -> dict:\n",
    "    \"\"\"\n",
    "    Pregunta al usuario si quiere filtrar por autor o Ãºltimo libro leÃ­do.\n",
    "    Devuelve un diccionario con filtros a aplicar.\n",
    "    \"\"\"\n",
    "    filters = {}\n",
    "    \n",
    "    author = input(\"ðŸ‘©â€ðŸ’» Do you have an author in mind? (leave empty if not): \").strip()\n",
    "    if author:\n",
    "        filters[\"author\"] = author.lower()\n",
    "    \n",
    "    last_book = input(\"ðŸ“– What was the last book you read? (leave empty if not relevant): \").strip()\n",
    "    if last_book:\n",
    "        filters[\"last_book\"] = last_book.lower()\n",
    "    \n",
    "    return filters\n",
    "\n",
    "\n",
    "def filter_results(df, filters):\n",
    "    \"\"\"\n",
    "    Aplica filtros de autor o Ãºltimo libro sobre los resultados de FAISS.\n",
    "    \"\"\"\n",
    "    results = df\n",
    "    \n",
    "    # Filtra por autor, si el usuario eligiÃ³ alguno\n",
    "    if \"author\" in filters:\n",
    "        results = results[results[\"authors\"].str.lower().str.contains(filters[\"author\"])]\n",
    "    \n",
    "    # Filtra por Ãºltimo libro, si el usuario eligiÃ³ alguno\n",
    "    if \"last_book\" in filters:\n",
    "        mask_to_exclude = results[\"title\"].str.lower().str.contains(filters[\"last_book\"])\n",
    "        results = results[~mask_to_exclude]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Consulta del usuario\n",
    "query_usuario = input(\"ðŸ”Ž Enter your request: \")\n",
    "query_final = build_expanded_query(query_usuario)\n",
    "query_embedding = model.encode([query_final], normalize_embeddings=True)\n",
    "\n",
    "# Buscar los 100 mÃ¡s similares (Por si los filtros son restrictivos, en especial el de autor)\n",
    "k = 100\n",
    "distances, indices = index.search(query_embedding.astype(\"float32\"), k)\n",
    "\n",
    "# Genero un dataframe con los 100 libros mÃ¡s parecidos\n",
    "results_df = df.iloc[indices[0]].copy()\n",
    "results_df[\"similarity\"] = distances[0]\n",
    "\n",
    "# Preguntar filtros adicionales\n",
    "apply_filters = input(\"âš™ï¸ Would you like to add filters (author, last book)? (y/n): \").strip().lower()\n",
    "\n",
    "if apply_filters == \"y\":\n",
    "    filters = ask_filters()\n",
    "else:\n",
    "    filters = {}\n",
    "\n",
    "# Aplicar filtros sobre candidatos\n",
    "filtered_df = filter_results(results_df, filters)\n",
    "\n",
    "# Preguntar si el usuario valora el rating\n",
    "consider_rating = input(\"â­ Do you care about the book's rating? (y/n): \").strip().lower()\n",
    "\n",
    "if consider_rating == \"y\":\n",
    "    # Normalizar ratings entre 0 y 1 (de forma robusta)\n",
    "    if filtered_df[\"avg_rating\"].notna().any():\n",
    "        min_r, max_r = filtered_df[\"avg_rating\"].min(), filtered_df[\"avg_rating\"].max()\n",
    "        if max_r > min_r:\n",
    "            filtered_df[\"rating_norm\"] = (filtered_df[\"avg_rating\"] - min_r) / (max_r - min_r)\n",
    "        else:\n",
    "            filtered_df[\"rating_norm\"] = 0.5  # todos iguales, neutral\n",
    "    else:\n",
    "        filtered_df[\"rating_norm\"] = 0.2\n",
    "\n",
    "    # Ajustar la similitud ponderando con el rating\n",
    "    filtered_df[\"similarity\"] = (\n",
    "        0.9 * filtered_df[\"similarity\"] + 0.1 * filtered_df[\"rating_norm\"]\n",
    "    )\n",
    "\n",
    "    # Reordenar resultados segÃºn la similitud ajustada\n",
    "    filtered_df = filtered_df.sort_values(by=\"similarity\", ascending=False)\n",
    "\n",
    "if len(filtered_df) == 0:\n",
    "    print(\"ðŸ˜” Sorry, we couldnâ€™t find a book that matches your request.\")\n",
    "elif len(filtered_df) < 5:\n",
    "    print(f\"â„¹ï¸ We only found {len(filtered_df)} book{'s' if len(filtered_df) != 1 else ''} that matched your request\")\n",
    "    \n",
    "\n",
    "# Mostrar resultados (top 5 despuÃ©s de filtrar)\n",
    "for i, (_, row) in enumerate(filtered_df.head(5).iterrows()):\n",
    "    print(f\"\\nRank {i+1}: {row['title']} - {row['authors']}\")\n",
    "    print(f\"Score (similarity): {row['similarity']:.3f}\")\n",
    "    print(f\"Rating: {row.get('avg_rating', 'N/A'):.2f}\")\n",
    "    print(f\"DescripciÃ³n: {row['description'][:200]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
