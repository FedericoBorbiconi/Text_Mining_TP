{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d222ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FBorbiconi\\anaconda3\\envs\\text_mining\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libros despu√©s del filtrado: 43837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1370/1370 [38:15<00:00,  1.68s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (43837, 384)\n",
      "Total libros indexados: 43837\n",
      "‚úÖ √çndice y metadata guardados\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "\n",
    "# 1. Cargar dataset\n",
    "df = pd.read_csv(\"fiction_books_clean.csv\")\n",
    "\n",
    "# 2. Eliminar libros sin descripci√≥n (Reemplazar por la limpieza de Noe)\n",
    "df = df.dropna(subset=[\"description\"])\n",
    "df = df[df[\"description\"].str.strip() != \"\"]\n",
    "print(\"Libros despu√©s del filtrado:\", len(df))\n",
    "\n",
    "\n",
    "# 3. Generar embeddings\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=\"cpu\")\n",
    "\n",
    "# Convertimos todas las descripciones en embeddings\n",
    "embeddings = model.encode(\n",
    "    df[\"description\"].tolist(),\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32,\n",
    "    normalize_embeddings=True  # normaliza a norma 1 ‚Üí m√°s f√°cil similitud coseno\n",
    ")\n",
    "\n",
    "embeddings = np.array(embeddings).astype(\"float32\")\n",
    "print(\"Embeddings shape:\", embeddings.shape)  # (n_libros, 384)\n",
    "\n",
    "\n",
    "# 4. Crear √≠ndice FAISS\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner Product (como coseno si est√° normalizado)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"Total libros indexados:\", index.ntotal)\n",
    "\n",
    "# 5. Guardar para usar luego\n",
    "faiss.write_index(index, \"libros_clean.index\")\n",
    "df.to_parquet(\"libros_clean_metadata.parquet\", engine=\"fastparquet\", index=False)\n",
    "\n",
    "print(\"‚úÖ √çndice y metadata guardados\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea372021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FBorbiconi\\anaconda3\\envs\\text_mining\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Your query was too short, to offer you better recomendations please answer a few more questions...\n",
      "\n",
      "\n",
      "‚úÖ Expanded query: A fantasy story set in small town, featuring adult characters, with a dark tone.\n",
      "\n",
      "\n",
      "Rank 1: Wildwood Imperium (Wildwood Chronicles #3) - Colin Meloy\n",
      "Score (similarity): 0.597\n",
      "Rating: 5.00\n",
      "Descripci√≥n: A young girl's midnight s√©ance awakens a long-slumbering malevolent spirit.... A band of runaway orphans allies with an underground collective of saboteurs and plans a daring rescue of their friends, ...\n",
      "\n",
      "Rank 2: Winesburg, Ohio - Sherwood Anderson\n",
      "Score (similarity): 0.558\n",
      "Rating: 3.29\n",
      "Descripci√≥n: A unified collection of short stories about life in a small town in the American Midwest....\n",
      "\n",
      "Rank 3: Sunshine sketches of a little town - Stephen Leacock\n",
      "Score (similarity): 0.557\n",
      "Rating: 5.00\n",
      "Descripci√≥n: \"Set in the fictional landscape of Mariposa on the shores of Lake Wissanotti in Missinaba County, Leacock's Sunshine Sketches of A Little Town is an affectionate satire of small town life. This series...\n",
      "\n",
      "Rank 4: Noisy Outlaws, Unfriendly Blobs, and Some Other Things . . - Ted Thompson, Eli Horowitz, Lemony Snicket, Nick Hornsby, George Saunders\n",
      "Score (similarity): 0.551\n",
      "Rating: 3.50\n",
      "Descripci√≥n: A collection of stories for wise young people and immature old people!A collection of stories for wise young people and immature old people, written by today's best authors spinning new tales. Each st...\n",
      "\n",
      "Rank 5: KƒÅmar≈´pa kataika·∏∑ - Charu Nivedita\n",
      "Score (similarity): 0.537\n",
      "Rating: 5.00\n",
      "Descripci√≥n: Novel based on sex stories....\n"
     ]
    }
   ],
   "source": [
    "# Esto no es necesario si corriste celda anterior\n",
    "######\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=\"cpu\")\n",
    "######\n",
    "\n",
    "# Cargar lo guardado\n",
    "index = faiss.read_index(\"libros_clean.index\")\n",
    "df = pd.read_parquet(\"libros_clean_metadata.parquet\", engine=\"fastparquet\")\n",
    "\n",
    "\n",
    "# Enriquecedor de query\n",
    "def build_expanded_query(query: str) -> str:\n",
    "    \"\"\"\n",
    "    If the query is short (<40 characters), ask for more details\n",
    "    and build an enriched query in English.\n",
    "    \"\"\"\n",
    "    if len(query.strip()) < 40:\n",
    "        print(\"‚ö†Ô∏è Your query was too short, to offer you better recomendations please answer a few more questions...\\n\")\n",
    "        \n",
    "        genre = input(\"üìö Which genre are you looking for? (e.g., romance, fantasy, mystery): \")\n",
    "        place = input(\"üåç Where should the story take place? (e.g., small town, big city, magical kingdom, outer space, historical setting): \")\n",
    "        characters = input(\"üë§ What kind of characters? (e.g., teenagers, heroes, families): \")\n",
    "        tone = input(\"üé≠ What tone do you prefer? (e.g., dramatic, funny, dark, hopeful): \")\n",
    "        \n",
    "        query_expanded = (\n",
    "            f\"A {genre} story set in {place}, featuring {characters} characters, with a {tone} tone.\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n‚úÖ Expanded query: {query_expanded}\\n\")\n",
    "        return query_expanded\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\nüë§ User query: {query}\")\n",
    "\n",
    "    return query.strip()\n",
    "\n",
    "# Filtros de b√∫squeda\n",
    "def ask_filters() -> dict:\n",
    "    \"\"\"\n",
    "    Pregunta al usuario si quiere filtrar por autor o √∫ltimo libro le√≠do.\n",
    "    Devuelve un diccionario con filtros a aplicar.\n",
    "    \"\"\"\n",
    "    filters = {}\n",
    "    \n",
    "    author = input(\"üë©‚Äçüíª Do you have an author in mind? (leave empty if not): \").strip()\n",
    "    if author:\n",
    "        filters[\"author\"] = author.lower()\n",
    "    \n",
    "    last_book = input(\"üìñ What was the last book you read? (leave empty if not relevant): \").strip()\n",
    "    if last_book:\n",
    "        filters[\"last_book\"] = last_book.lower()\n",
    "    \n",
    "    return filters\n",
    "\n",
    "\n",
    "def filter_results(df, filters):\n",
    "    \"\"\"\n",
    "    Aplica filtros de autor o √∫ltimo libro sobre los resultados de FAISS.\n",
    "    \"\"\"\n",
    "    results = df\n",
    "    \n",
    "    # Filtra por autor, si el usuario eligi√≥ alguno\n",
    "    if \"author\" in filters:\n",
    "        results = results[results[\"authors\"].str.lower().str.contains(filters[\"author\"])]\n",
    "    \n",
    "    # Filtra por √∫ltimo libro, si el usuario eligi√≥ alguno\n",
    "    if \"last_book\" in filters:\n",
    "        mask_to_exclude = results[\"title\"].str.lower().str.contains(filters[\"last_book\"])\n",
    "        results = results[~mask_to_exclude]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Consulta del usuario\n",
    "query_usuario = input(\"üîé Enter your request: \")\n",
    "query_final = build_expanded_query(query_usuario)\n",
    "query_embedding = model.encode([query_final], normalize_embeddings=True)\n",
    "\n",
    "# Buscar los 100 m√°s similares (Por si los filtros son restrictivos, en especial el de autor)\n",
    "k = 100\n",
    "distances, indices = index.search(query_embedding.astype(\"float32\"), k)\n",
    "\n",
    "# Genero un dataframe con los 100 libros m√°s parecidos\n",
    "results_df = df.iloc[indices[0]].copy()\n",
    "results_df[\"similarity\"] = distances[0]\n",
    "\n",
    "# Preguntar filtros adicionales\n",
    "apply_filters = input(\"‚öôÔ∏è Would you like to add filters (author, last book)? (y/n): \").strip().lower()\n",
    "\n",
    "if apply_filters == \"y\":\n",
    "    filters = ask_filters()\n",
    "else:\n",
    "    filters = {}\n",
    "\n",
    "# Aplicar filtros sobre candidatos\n",
    "filtered_df = filter_results(results_df, filters)\n",
    "\n",
    "# Preguntar si el usuario valora el rating\n",
    "consider_rating = input(\"‚≠ê Do you care about the book's rating? (y/n): \").strip().lower()\n",
    "\n",
    "if consider_rating == \"y\":\n",
    "    # Normalizar ratings entre 0 y 1 (de forma robusta)\n",
    "    if filtered_df[\"avg_rating\"].notna().any():\n",
    "        min_r, max_r = filtered_df[\"avg_rating\"].min(), filtered_df[\"avg_rating\"].max()\n",
    "        if max_r > min_r:\n",
    "            filtered_df[\"rating_norm\"] = (filtered_df[\"avg_rating\"] - min_r) / (max_r - min_r)\n",
    "        else:\n",
    "            filtered_df[\"rating_norm\"] = 0.5  # todos iguales, neutral\n",
    "    else:\n",
    "        filtered_df[\"rating_norm\"] = 0.2\n",
    "\n",
    "    # Ajustar la similitud ponderando con el rating\n",
    "    filtered_df[\"similarity\"] = (\n",
    "        0.9 * filtered_df[\"similarity\"] + 0.1 * filtered_df[\"rating_norm\"]\n",
    "    )\n",
    "\n",
    "    # Reordenar resultados seg√∫n la similitud ajustada\n",
    "    filtered_df = filtered_df.sort_values(by=\"similarity\", ascending=False)\n",
    "\n",
    "if len(filtered_df) == 0:\n",
    "    print(\"üòî Sorry, we couldn‚Äôt find a book that matches your request.\")\n",
    "elif len(filtered_df) < 5:\n",
    "    print(f\"‚ÑπÔ∏è We only found {len(filtered_df)} book{'s' if len(filtered_df) != 1 else ''} that matched your request\")\n",
    "    \n",
    "\n",
    "# Mostrar resultados (top 5 despu√©s de filtrar)\n",
    "for i, (_, row) in enumerate(filtered_df.head(5).iterrows()):\n",
    "    print(f\"\\nRank {i+1}: {row['title']} - {row['authors']}\")\n",
    "    print(f\"Score (similarity): {row['similarity']:.3f}\")\n",
    "    print(f\"Rating: {row.get('avg_rating', 'N/A'):.2f}\")\n",
    "    print(f\"Descripci√≥n: {row['description'][:200]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
